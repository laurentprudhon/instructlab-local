{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79e0989-feba-4f18-a754-856427aca303",
   "metadata": {},
   "source": [
    "# Instructlab local - 02 Test inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f29e0-f67d-4920-9510-7646222082fa",
   "metadata": {},
   "source": [
    "## 1. VLLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cec0a20-5a4b-4b59-b1cb-794470b6e223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:24:49.557762Z",
     "iopub.status.busy": "2024-05-26T15:24:49.557658Z",
     "iopub.status.idle": "2024-05-26T15:24:49.561180Z",
     "shell.execute_reply": "2024-05-26T15:24:49.560772Z",
     "shell.execute_reply.started": "2024-05-26T15:24:49.557750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "\"mistral\":\"mistralai/Mistral-7B-v0.3\",\n",
    "\"mistral-instruct\":\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "\"llama3\":\"meta-llama/Meta-Llama-3-8B\",\n",
    "\"llama3-instruct\":\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "\"phi3-mini\":\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "\"phi3-small\":\"microsoft/Phi-3-small-8k-instruct\",\n",
    "\"mixtral-q3\":\"mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-3bit-metaoffload-HQQ\",\n",
    "\"mixtral-q2\":\"mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-2bit_g16_s128-HQQ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29a6b4-09aa-4217-8222-8779195f456c",
   "metadata": {},
   "source": [
    "**IMPORTANT: always set the local download cache directory explicitly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8eb5493-b4a5-4ef0-b989-530bae9df9b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:24:49.562029Z",
     "iopub.status.busy": "2024-05-26T15:24:49.561799Z",
     "iopub.status.idle": "2024-05-26T15:24:49.580554Z",
     "shell.execute_reply": "2024-05-26T15:24:49.580078Z",
     "shell.execute_reply.started": "2024-05-26T15:24:49.562015Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download cache dir: /models/huggingface/transformers OK\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_CACHE_DIR = \"/models/huggingface/transformers\"\n",
    "\n",
    "from pathlib import Path\n",
    "print(f\"Download cache dir: {DOWNLOAD_CACHE_DIR} {('OK' if Path(DOWNLOAD_CACHE_DIR).exists() else 'KO')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ee6086-e2fa-41a0-9dbc-6cca44a0bf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:26:03.763037Z",
     "iopub.status.busy": "2024-05-26T15:26:03.762928Z",
     "iopub.status.idle": "2024-05-26T15:26:03.766495Z",
     "shell.execute_reply": "2024-05-26T15:26:03.766056Z",
     "shell.execute_reply.started": "2024-05-26T15:26:03.763029Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can then check the download_config of VLLM with :\n",
    "# llm.llm_engine.load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fc852-9777-46e4-87bb-b1c7e2512cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:10:43.923375Z",
     "iopub.status.busy": "2024-05-25T16:10:43.920040Z",
     "iopub.status.idle": "2024-05-25T16:10:43.974118Z",
     "shell.execute_reply": "2024-05-25T16:10:43.973099Z",
     "shell.execute_reply.started": "2024-05-25T16:10:43.922598Z"
    },
    "tags": []
   },
   "source": [
    "### 1.1 Mistral 7B instruct v0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698e27a-60f7-4dd9-a22f-66246baf602f",
   "metadata": {},
   "source": [
    "***TEMPORARY BUG FIX for Mistral 7B v0.3*** with VLLM v0.4.2\n",
    "\n",
    "https://github.com/vllm-project/vllm/pull/5005\n",
    "\n",
    "vi /workspace/instructlab-local/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\n",
    "\n",
    "vi /workspace/instructlab-local/.venv/lib/python3.10/site-packages/vllm/model_executor/model_loader/weight_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c932f200-a455-4180-9055-ca972b699b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:24:49.581086Z",
     "iopub.status.busy": "2024-05-26T15:24:49.580978Z",
     "iopub.status.idle": "2024-05-26T15:26:03.751734Z",
     "shell.execute_reply": "2024-05-26T15:26:03.751242Z",
     "shell.execute_reply.started": "2024-05-26T15:24:49.581077Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/instructlab-local/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model mistralai/Mistral-7B-Instruct-v0.3\n",
      "WARNING 05-26 15:24:51 utils.py:327] Not found nvcc in /usr/local/cuda. Skip cuda version check!\n",
      "INFO 05-26 15:24:51 config.py:379] Using fp8 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. But it may cause slight accuracy drop without scaling factors. FP8_E5M2 (without scaling) is only supported on cuda version greater than 11.8. On ROCm (AMD GPU), FP8_E4M3 is instead supported for common inference criteria.\n",
      "INFO 05-26 15:24:51 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/models/huggingface/transformers', load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=fp8, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=mistralai/Mistral-7B-Instruct-v0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/instructlab-local/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-26 15:24:51 utils.py:660] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "WARNING 05-26 15:24:51 utils.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 05-26 15:24:51 selector.py:27] Using FlashAttention-2 backend.\n",
      "INFO 05-26 15:24:52 weight_utils.py:200] Using model weights format ['*.safetensors']\n",
      "INFO 05-26 15:25:53 model_runner.py:175] Loading model weights took 13.5083 GB\n",
      "INFO 05-26 15:25:58 gpu_executor.py:114] # GPU blocks: 6129, # CPU blocks: 4096\n",
      "INFO 05-26 15:25:58 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-26 15:25:58 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-26 15:26:03 model_runner.py:1017] Graph capturing finished in 5 secs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_name = models[\"mistral-instruct\"]\n",
    "\n",
    "print(f\"Loading model {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm = LLM(model_name, kv_cache_dtype=\"fp8\", gpu_memory_utilization=0.99, download_dir=DOWNLOAD_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b74b0-f4cc-4f04-ab87-535a6cac1c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install mistral_common==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdb123a-ca7c-491f-9ffd-5231b7a8f0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:36:34.248249Z",
     "iopub.status.busy": "2024-05-26T15:36:34.247154Z",
     "iopub.status.idle": "2024-05-26T15:36:34.644886Z",
     "shell.execute_reply": "2024-05-26T15:36:34.644242Z",
     "shell.execute_reply.started": "2024-05-26T15:36:34.248207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3117016d3e4d7f8fe9c335237460a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/models/huggingface/transformers/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/83e9aa141f2e28c82232fea5325f54edf17c43de/tokenizer.model.v3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils.hub import cached_file \n",
    "\n",
    "tokenizer_model_file = cached_file(model_name, \"tokenizer.model.v3\", cache_dir=DOWNLOAD_CACHE_DIR)\n",
    "tokenizer_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df31fb71-7374-4f22-a17a-52983ba3bc94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:37:09.197645Z",
     "iopub.status.busy": "2024-05-26T15:37:09.196597Z",
     "iopub.status.idle": "2024-05-26T15:37:09.280139Z",
     "shell.execute_reply": "2024-05-26T15:37:09.279714Z",
     "shell.execute_reply.started": "2024-05-26T15:37:09.197604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "\n",
    "tokenizer = MistralTokenizer.from_file(tokenizer_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f84a83a5-2bcf-43c2-a4b6-29479ecfbe73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:39:30.321017Z",
     "iopub.status.busy": "2024-05-26T15:39:30.320558Z",
     "iopub.status.idle": "2024-05-26T15:39:30.326824Z",
     "shell.execute_reply": "2024-05-26T15:39:30.326282Z",
     "shell.execute_reply.started": "2024-05-26T15:39:30.320987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST]▁quelles▁sont▁les▁principales▁ouvertures▁des▁échecs▁?[/INST]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"quelles sont les principales ouvertures des échecs ?\")])\n",
    "\n",
    "tokens = tokenizer.encode_chat_completion(completion_request)\n",
    "tokens.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09c1a46-9d3f-4c25-813c-7c9b45025f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T15:39:46.802375Z",
     "iopub.status.busy": "2024-05-26T15:39:46.801896Z",
     "iopub.status.idle": "2024-05-26T15:39:58.297870Z",
     "shell.execute_reply": "2024-05-26T15:39:58.297372Z",
     "shell.execute_reply.started": "2024-05-26T15:39:46.802343Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 tokens generated in 11.488973617553711 sec\n",
      " Les principales ouvertures des échecs, également appelées systèmes d'ouverture, sont :\n",
      "\n",
      "1. Défense française (1. e4 e6)\n",
      "2. Défense sicilienne (1. e4 c5)\n",
      "3. Défense indienne (1. d4 Cf6)\n",
      "4. Défense espagnole (1. e4 e5 2. Cf3 Cc6)\n",
      "5. Défense Caro-Kann (1. e4 c6)\n",
      "6. Défense Grünfeld (1. d4 Cf6 2. c4 g6 3. Cc3 d5)\n",
      "7. Défense russe (1. d4 d5)\n",
      "8. Défense scandinave (1. e4 d5)\n",
      "9. Défense benoni (1. d4 Cf6 2. c4 c5)\n",
      "10. Défense philidorienne (1. e4 e5 2. Cf3 d6 3. d4)\n",
      "11. Défense du roi (1. d4 d5 2. c4 dxc4 3. a4)\n",
      "12. Défense sicilienne, variante Najdorf (1. e4 c5 2. d4 cxd4 3. Cc3 dxc3 4. Cxc3 a6)\n",
      "13. Défense sicilienne, variante Scheveningen (1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 a6)\n",
      "14. Défense sicilienne, variante Dragon (1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 g6 6. Be3 Gg7 7. Fd3 O-O 8. O-O d5)\n",
      "15. Défense sicilienne, variante Najdorf, variante de la Main-Pari (1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 a6 6. Be3 e6 7. O-O h6 8. Fd3 d5)\n",
      "\n",
      "Ces ouvertures sont les plus populaires et les plus étudiées dans les parties de haut niveau. Chaque ouverture a ses propres particularités et possibilités stratégiques, et il est important de comprendre les principales idées de chaque ouverture pour pouvoir jouer ou défendre efficacement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_tokens = 1024\n",
    "sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=max_tokens)\n",
    "\n",
    "requests_results = llm.generate(tokens.text, sampling_params=sampling_params)\n",
    "result = requests_results[0]\n",
    "output = result.outputs[0]\n",
    "print(f\"{len(output.token_ids)} tokens generated in {result.metrics.finished_time-result.metrics.arrival_time} sec\")\n",
    "print(output.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d92b8f1-ecdd-49f5-bf07-0d61bf58c31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T20:03:16.197886Z",
     "iopub.status.busy": "2024-05-25T20:03:16.197388Z",
     "iopub.status.idle": "2024-05-25T20:03:16.213733Z",
     "shell.execute_reply": "2024-05-25T20:03:16.213118Z",
     "shell.execute_reply.started": "2024-05-25T20:03:16.197853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RequestOutput(request_id=1, prompt='quelles sont les principales ouvertures des échecs ?', prompt_token_ids=[128000, 447, 37907, 15132, 3625, 82512, 6033, 1653, 1439, 951, 4046, 331, 54817, 949], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\" ( French )\\nWhat are the main openings in chess?\\nThere are many openings in chess, and it's difficult to give a complete list. However, here are some of the most popular and well-known openings:\\n1. Ruy Lopez: This is one of the oldest and most popular openings, named after the 16th-century Spanish priest Ruy Lopez de Segura. It starts with the moves 1.e4 e5 2.Nf3 Nc6 3.Bb5.\\n2. Sicilian Defense: This is one of the most aggressive and complex openings, starting with the moves 1.e4 c5. It's a favorite among many top players.\\n3. Italian Game: This opening starts with the moves 1.e4 e5 2.Nf3 Nc6 3.Bc4, aiming to quickly develop the bishop and knight.\\n4. King's Pawn Opening: This is one of the simplest and most common openings, starting with the moves 1.e4. It's often used by beginners and intermediate players.\\n5. Queen's Pawn Opening: This opening starts with the moves 1.d4, aiming to control the center of the board and create space for the pieces.\\n6. Slav Defense: This is a solid and positional opening, starting with the moves 1.d4 d5 2.c4 c6. It's a favorite among many players who prefer a slow-paced game.\\n7. Caro-Kann Defense: This is another solid and positional opening, starting with the moves 1.e4 c6. It's a good choice for players who want to play a quiet game.\\n8. French Defense: This is an aggressive and complex opening, starting with the moves 1.e4 e6. It's a favorite among many top players.\\n9. Alekhine's Defense: This is an aggressive and unorthodox opening, starting with the moves 1.e4 Nf6. It's a good choice for players who want to surprise their opponents.\\n10. Scotch Game: This is a solid and positional opening, starting with the moves 1.e4 e5 2.Nf3 Nc6 3.d4. It's a good choice for players who want to play a slow-paced game.\\n\\nOf course, this is not an exhaustive list, and there are many other openings to explore. As you improve your chess skills, you'll discover more openings and learn how to use them effectively.\", token_ids=[320, 8753, 1763, 3923, 527, 279, 1925, 49649, 304, 33819, 5380, 3947, 527, 1690, 49649, 304, 33819, 11, 323, 433, 596, 5107, 311, 3041, 264, 4686, 1160, 13, 4452, 11, 1618, 527, 1063, 315, 279, 1455, 5526, 323, 1664, 22015, 49649, 512, 16, 13, 432, 4168, 45315, 25, 1115, 374, 832, 315, 279, 24417, 323, 1455, 5526, 49649, 11, 7086, 1306, 279, 220, 845, 339, 34457, 15506, 28185, 432, 4168, 45315, 409, 17652, 5808, 13, 1102, 8638, 449, 279, 11031, 220, 16, 1770, 19, 384, 20, 220, 17, 2112, 69, 18, 452, 66, 21, 220, 18, 1823, 65, 20, 627, 17, 13, 56954, 69183, 16777, 25, 1115, 374, 832, 315, 279, 1455, 19738, 323, 6485, 49649, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 272, 20, 13, 1102, 596, 264, 7075, 4315, 1690, 1948, 4311, 627, 18, 13, 15155, 4140, 25, 1115, 8736, 8638, 449, 279, 11031, 220, 16, 1770, 19, 384, 20, 220, 17, 2112, 69, 18, 452, 66, 21, 220, 18, 1823, 66, 19, 11, 38178, 311, 6288, 2274, 279, 54306, 323, 47709, 627, 19, 13, 6342, 596, 83971, 41137, 25, 1115, 374, 832, 315, 279, 45648, 323, 1455, 4279, 49649, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 13, 1102, 596, 3629, 1511, 555, 47950, 323, 29539, 4311, 627, 20, 13, 16657, 596, 83971, 41137, 25, 1115, 8736, 8638, 449, 279, 11031, 220, 16, 962, 19, 11, 38178, 311, 2585, 279, 4219, 315, 279, 4580, 323, 1893, 3634, 369, 279, 9863, 627, 21, 13, 120859, 16777, 25, 1115, 374, 264, 6573, 323, 68647, 8736, 11, 6041, 449, 279, 11031, 220, 16, 962, 19, 294, 20, 220, 17, 522, 19, 272, 21, 13, 1102, 596, 264, 7075, 4315, 1690, 4311, 889, 10932, 264, 6435, 65319, 1847, 627, 22, 13, 3341, 78, 16222, 1036, 16777, 25, 1115, 374, 2500, 6573, 323, 68647, 8736, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 272, 21, 13, 1102, 596, 264, 1695, 5873, 369, 4311, 889, 1390, 311, 1514, 264, 11594, 1847, 627, 23, 13, 8753, 16777, 25, 1115, 374, 459, 19738, 323, 6485, 8736, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 384, 21, 13, 1102, 596, 264, 7075, 4315, 1690, 1948, 4311, 627, 24, 13, 19623, 31764, 483, 596, 16777, 25, 1115, 374, 459, 19738, 323, 653, 2419, 31162, 8736, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 452, 69, 21, 13, 1102, 596, 264, 1695, 5873, 369, 4311, 889, 1390, 311, 13051, 872, 19949, 627, 605, 13, 93050, 4140, 25, 1115, 374, 264, 6573, 323, 68647, 8736, 11, 6041, 449, 279, 11031, 220, 16, 1770, 19, 384, 20, 220, 17, 2112, 69, 18, 452, 66, 21, 220, 18, 962, 19, 13, 1102, 596, 264, 1695, 5873, 369, 4311, 889, 1390, 311, 1514, 264, 6435, 65319, 1847, 382, 2173, 3388, 11, 420, 374, 539, 459, 73603, 1160, 11, 323, 1070, 527, 1690, 1023, 49649, 311, 13488, 13, 1666, 499, 7417, 701, 33819, 7512, 11, 499, 3358, 7142, 810, 49649, 323, 4048, 1268, 311, 1005, 1124, 13750, 13, 128009], cumulative_logprob=-52.11397035419941, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1716667369.4943094, last_token_time=1716667369.4943094, first_scheduled_time=1716667369.4986632, first_token_time=1716667369.8480308, time_in_queue=0.004353761672973633, finished_time=1716667379.2284214), lora_request=None)]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3bd1f6-2916-4507-b090-705fdf69089a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T17:22:36.425088Z",
     "iopub.status.busy": "2024-05-25T17:22:36.424615Z",
     "iopub.status.idle": "2024-05-25T17:22:36.437659Z",
     "shell.execute_reply": "2024-05-25T17:22:36.437186Z",
     "shell.execute_reply.started": "2024-05-25T17:22:36.425058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mLLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_tokenizer_init\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquantization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrevision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer_revision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mswap_space\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menforce_eager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_context_len_to_capture\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_seq_len_to_capture\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_custom_all_reduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Initialize self.  See help(type(self)) for accurate signature.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtokenizer_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mskip_tokenizer_init\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mquantization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrevision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtokenizer_revision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mswap_space\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0menforce_eager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_context_len_to_capture\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_seq_len_to_capture\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdisable_custom_all_reduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"disable_log_stats\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"disable_log_stats\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mengine_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEngineArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mskip_tokenizer_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_tokenizer_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_parallel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mquantization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer_revision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer_revision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_memory_utilization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mswap_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0menforce_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menforce_eager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_context_len_to_capture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_context_len_to_capture\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmax_seq_len_to_capture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_seq_len_to_capture\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdisable_custom_all_reduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_custom_all_reduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_engine_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mengine_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUsageContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLLM_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /workspace/instructlab-local/.venv/lib/python3.10/site-packages/vllm/entrypoints/llm.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for response_chunk in response_generator:\n",
    "    print(response_chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd79f3-5570-404e-b693-c209bf943c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "prompt = \"Quels sont les avantages du Crédit Mutuel ?\"\n",
    "\n",
    "# System prompt\n",
    "messages = [\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages du Crédit Agricole ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Société Générale ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la BNP ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Banque populaire ?\"}\n",
    "],\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"Tu es un assistant utile et professionnel qui répond toujours en français.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Quels sont les avantages de la Caise d'épargne ?\"}\n",
    "]\n",
    "]\n",
    "\n",
    "# Generate outputs\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "outputs = llm.generate(text, sampling_params)\n",
    "end_time = time.time()  # Record the end time\n",
    "    \n",
    "# Print the outputs.\n",
    "tokenscount = 0\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    tokenscount = tokenscount + len(output.outputs[0].token_ids)\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n",
    "    \n",
    "print(f\"Performance: {int(tokenscount/(end_time-start_time))} tokens/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructlab-local",
   "language": "python",
   "name": "instructlab-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
